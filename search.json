[{"title":"论文 - 通过非线性随机邻近嵌入自动分类细胞表达","url":"%2F2018%2F06%2FAutomatic-classification-of-cellular-expression-by-nonlinear-stochastic-embedding.html","content":"\n{% note default %}\n原文：Automatic classification of cellular expression by nonlinear stochastic embedding (ACCENSE)  \n作者：Karthik Shekhar, Petter Brodin, Mark M.Davis and Arup K.Chakraborty.  \n来源：Proceedings of the National Academy of Sciences (PNAS), 2014, 111(1): 202-207.  \n{% endnote %}\n\n## 摘要\n\n质谱流式细胞技术 (Mass cytometry) 能够在单细胞水平上测试近 40 种不同的蛋白质，即提供前所未有的多维信息水平。由于各式各样的细胞种群数据集的复杂性，要收集有用的生物学知识对计算工具也有新的要求。回顾之前的聚类方法，即对于不同功能的细胞识别是基于细胞表征相似性来实现区分的。当然，经典方法存在一定局限性，例如单细胞分辨率的损失；经典方法需要预知簇中的对象数量 (本文中指细胞亚群的规模数量)。\n\n<!-- More -->\n\n则该论文引入 `ACCENSE` (Automatic classification of cellular expression by nonlinear stochastic embedding) 高维单细胞数据分析工具：\n\n- 基于密度划分的非线性降维方法，降维步骤采用 `t-Distributed Stochastic Neighbor Embedding (t-SNE)` 算法 $^{[1]}$。\n- 探索性数据分析，同时避免任何手动 `阀门(阈值)` 的需要，即有别于基于距离的方法 (离群点判定)、基于密度的方法 (密度阈值)。\n- 化繁为简，在二维或三维图上展示多元细胞的表型。\n\n再有，本论文将 ACCENSE 应用于 35 参数的质谱流式细胞技术，检测 CD8+ T 细胞的数量 (数据来自于特定的无病原和无菌小鼠)，并将细胞分层到表型亚群中。即对于具体的聚类算法、降维算法中，特定的符号名称会以具体的对象名称替代。\n\n## 正文\n\n### 背景介绍\n- 免疫系统包含了许多类型的细胞，它们在免疫应答过程中表现出多样化的功能和复杂方式的相互作用，即通过不同蛋白质的表达水平所定义，故个体细胞的功能与其细胞表型密切相关。这里启示我们，对于不同功能的细胞可通过细胞表型相似性进行聚类区分。\n\n- 传统流式细胞技术和质谱流式细胞技术\n\t- 传统流式细胞技术 (Flow Cytometry) $^{[2]}$ 中，用 `荧光基因` 标记的抗体染色，其蛋白质靶标通过单细胞分辨率的光发射信号进行量化。\n\n\t> 由于有限的光谱和重叠的发射信号，每个细胞限制为 12-16 个参数。\n\n\t- 质谱流式细胞技术 (Mass Cytometry) $^{[3]}$ ，使用 `金属螯合探针` 可以对多达 42 个参数的单个细胞进行量化。\n\n\t- 传统流式细胞技术和质谱流式细胞技术相比，主要有两点不同：  \n\t\t- 标签系统的不同，前者主要使用各种荧光基团作为抗体的标签，后者则使用各种金属元素作为标签；  \n\t\t- 检测系统的不同，前者使用激光器和光电倍增管，而后者使用 ICP 质谱技术。 \n\n### 聚类算法\n由 `质谱流式细胞技术产生的高维数据`，以具有生物学意义的方式解释是具有挑战性的。然而，很多聚类工具是基于细胞的蛋白表达相似性进行细胞分类的，例如：\n\n- `SPADE 算法` $^{[4,5]}$：SPADE 使用多元信息定义细胞簇，并在树状结构中显示潜在的表型层次结构。但尚有不足之处：\n\t- 一是单细胞分辨率的损失；\n\t- 二是对目标集群数量的需要预知。\n\n### 降维算法\n同样，降维算法以蛋白质表达相似性，把空间组织的细胞群在低维空间聚集成不同的细胞亚群。\t\n\t\n- `PCA 算法`：PCA降维的大致思想就是，挑选特征明显的、显得比较重要的信息保留下来。在本论文中，Newell 等人将主成分分析 (Principal component analysis，PCA) 应用于 25 参数的质谱流式细胞技术，检测人的 CD8+ T 细胞的数量，且使用前三种主成分 (3D-PCA) 分离细胞亚群。3D-PCA 以三个汇总变量表示数据，每个汇总变量都是原始维度的线性组合，并去捕获投影后数据的方差，直至其取值为最大值。然而，PCA 能在数据中所有的可能线性组合中找到最优表达，但也存在限制条件：线性投影可能太严格而不能产生精确的表示 $^{[6]}$ ( 引入 t-SNE 算法 )。\n- `t-SNE 算法` $^{[7]}$：t-Distributed Stochastic Neighbor Embedding，数据降维与可视化的方法，具体的算法细节如下：\n\t- 让 $\\{x^{(i)}\\}$ 表示归一化 n 维蛋白质表达向量编码的细胞 i 表型 (i=1, 2, ..., M)。\n\t- 若在 2D 平面图下，$\\{y^{(i)}\\}$ 向量表示高维 $\\{x^{(i)}\\}$ 对应于低维的映射，它使得具有相似表型的 T 细胞彼此靠近嵌入，表型不相似的则嵌入相对较远的距离。\n\t- 采用细胞 i 和 j 之间的成对概率 $\\{p_{i,j}\\}$ 表示 $\\{x^{(i)}\\}$ 与 $\\{x^{(j)}\\}$ 之间的相似性。\n\t- 若在 2D 平面图下，成对概率 $\\{q_{i,j}\\}$ 表示 $\\{y^{(i)}\\}$ 与 $\\{y^{(j)}\\}$ 之间的相似性。\n\t- 通过最小化 $\\{p_{i,j}\\}$ 与 $\\{q_{i,j}\\}$ 的 KL 散度 (可理解为代价函数)，然后找出嵌入向量 $\\{y^{(i)}\\}$，即它让高维转低维的表示信息能最大程度被保存下来。\n\t\n\t> KL 散度 ([详细见附录 1](#1-t-SNE-中的概率))，Kullback-Leibler Divergence，又称相对熵，即描述两概率分布 P 和 Q 的差异。KL 散度公式 (1) 如下：\n\t\n\t$$D_{KL}(\\{p_{i,j}\\}|\\{q_{i,j}\\}) = \\sum_{i,j} p_{i,j} log \\frac{p_{i,j}}{q_{i,j}} \\tag{1}$$\n\t\n\t- $\\{y^{(i)}\\}$ 可以编码非线性关系，不像 PCA 中被约束为 $\\{x^{(i)}\\}$ 的线性组合。\n\t- `最佳嵌入` 是通过数值梯度下降法来确定的，即所有数据点的 KL 散度总和减小到最小 ([详细见附录 2](#2-数值梯度下降法))。\n\n### 识别细胞亚群\n- 使用一个内核密度变换，从 t-SNE 的细胞散布图计算出一个复合图像 $K_\\gamma(y)$：\n\t$$K_\\gamma(y) = exp(\n\t-\\frac{||y - y'||^{2}}{2\\gamma^2}\n\t)\\tag{2}$$\n\t\n- 在本论文中，$K_\\gamma(y)$ 的 `局部最大值` 表示具有共同表型的 CD8+ T 细胞亚群，且使用了 matlab 的峰值检测算法识别这些局部最大值。\n\n\t> 当然，也可以在嵌入点上使用 K-Means 聚类算法来识别 T 细胞子集，但其要求事先指定簇的数量。\n\t\n- 如何求得 `局部最大值`，关键是对于公式 (2) 中 $\\gamma$ 的参数设定多少有关。即通过比较不同的核-宽带 $\\gamma$ 产生的结果，则存在一个 $\\gamma$ 值为表型空间中存在的局部和全局特征提供了准确的粗粒度表示。从图 1-2 中可得，即启示我们可以以数据驱动的方式，近似地识别 CD8+ T 细胞的亚群。\n\n### 相关图表\n\n- 如图 1-1 所示，ACCENSE 应用于质谱高维数据。\n\n![图1-1ACCENSE ACCENSE 应用于质谱高维数据](/images/illustration/Paper/2018/06/Automatic-classification-of-cellular-expression-by-nonlinear-stochastic-embedding_1-1.jpg)\n<center>图 1-1 ACCENSE 应用于质谱高维数据</center>\n\n(A) 质谱细胞计数数据集样本的图示。行对应于不同的细胞，而列对应于测量其表达 (细胞表面抗原和细胞内蛋白) 的不同标记的金属螯合抗体。每一元组对应于指示每个标记的表达水平的质荷比变换值 (反双曲函数)。(C) 来自SPF B6 小鼠的 CD8+ T 细胞的 2D t-SNE 图谱。每个点代表来自训练集的一个细胞 (M = 18304)，且数据点是通过对原始数据集进行下采样得到。(D) 通过使用基于内核密度变换 ($K_{\\gamma}(y)\\,{,}\\,\\gamma = 7$)，将细胞的局部概率密度嵌入 (C) 的复合图像。并使用标准的峰值检测算法进行识别局部最大值，在二维密度图表示表型亚群的中心。\n\n- 如图 1-2 所示，展示了峰值随着 $\\gamma$ 的增加而变化。\n\n![图1-2展示了峰值随着γ的增加而变化](/images/illustration/Paper/2018/06/Automatic-classification-of-cellular-expression-by-nonlinear-stochastic-embedding_1-2.png)\n<center>图 1-2 展示了峰值随着 $\\gamma$ 的增加而变化</center>\n\n\t\n## 附录\n\n### 1 t-SNE 中的概率\n\n#### $p_{i,j}$ 概率\n基于蛋白质相似性，设 $p_{j|i}$ (i,j = 1, 2, ..., M) 表示细胞 i 将选择细胞 j 作为其最近邻的概率 ( $p_{j|i}$ 越大，$x^{(i)} 和 x^{(j)}$ 越近 )：\n\n$$\np_{j|i} = \\frac{\n\texp({-d_{i,j}^2} / {\n\t2\\sigma_i^2})\n}{ \n\t\\sum_{k \\neq i} exp({-d_{i,k}^2} / {\n\t2\\sigma_i^2})\n}, d_{i,j} = ||x^{(i)} - x^{(j)}||_2\n\\tag{3}\n$$\n\n对于概率 $p_{j|i}$ 的几点说明：\n\n- $d_{i,j}$ 可以使用其他距离范式替代欧式距离范式；\n- 原始的 SNE 算法是不对称的，为简化梯度公式，t-SNE 中让公式 (3) 的条件概率是对称的。即初始化 $p_{i|i} = 0$，对于任意的 $p_{i|j} = p_{j|i}$，可得：\t\n$$\np_{i,j} = \\frac{\n\tp_{j|i} + p_{i|j} \n}{2M} = \\frac{\n\texp({-d_{i,j}^2} / {\n\t2\\sigma_i^2})\n}{ \n\t\\sum_{k \\neq i} exp({-d_{i,k}^2} / {\n\t2\\sigma_i^2})\n}\n\\tag{4}\n$$ \n\t\n- 不同的点 $x_i$，带宽 $\\sigma_i$ 的取值也是不同的。\n\t- 公式 (3) 中的带宽 $\\sigma_i$ 是确保对于每一个细胞都有相同的复杂度 (Complexity)。复杂度可理解为一个点附近的 `有效近邻点个数`。\n\t- 定义复杂度为 $P_i = 2^{H_{j|i}}$，其近似地解释为细胞 i 的最近邻点的数量。\n\t- 定义 $p_{j|i}$ 的香农熵 (信息熵) 为 $H_{j|i} = - \\sum_j p_{j|i} \\log_2 p_{j|i}$，且 $H_{j|i}$ 随着 $\\sigma_i$ 的增加而增加。\n\n\t\t> 在本论文中，t-SNE 图谱的复杂度被设定为 30，即 10-50 范围内的复杂度对最终结果的影响不大 (较好的鲁棒性)。\n\n#### $q_{i,j}$ 概率\n对于低维度下的 $\\{y_i\\}$，在原始的 SNE 算法 $^{[7]}$ 中 Hinton 和 Rowers 引用高斯核函数 (Gaussian Kernels) 定义 $q_{i,j}$，但在低维表达中发现了 `拥挤问题`。\n\n> `拥挤问题`：就是说各个簇聚集在一起，无法区分。譬如，有一高维度数据在降维到 10 维下可以有很好的表达，但是降维到两维后无法得到可信映射。具体情况是，10 维中有数个点之间两两等距离的，在二维下就无法得到可信的映射结果。  \n> 进一步说明，假设一个以数据点 $x^i$ 为中心，半径为 r 的 m 维球(三维空间就是球)，其体积是按 $r^m$ 增长的，假设数据点是在 m 维球中均匀分布的，我们来看看其他数据点与 $x^i$ 的距离随维度增大而产生的变化。\n\nt-SNE 减轻了拥挤问题，即使用更加偏重长尾分布的方式来将距离转换为概率分布 $^{[8]}$，故有 $q_{i,j}$：\n\n$$\nq_{i,j} = \\frac{\n\t(1 + \\Delta_{i,j}^2)^{-1}\n}{ \n\t\\sum_{k \\neq i} (1 + \\Delta_{i,k}^2)^{-1}\n}, \\Delta_{i,j} = ||y^{(i)} - y^{(j)}||_2\n\\tag{5}\n$$\n\n同样地，对于概率 $q_{i,j}$ 的几点说明：\n\n- $\\Delta_{i,j}$ 可以使用其他距离范式替代欧式距离范式；\n- 原始的 SNE 算法是不对称的，为简化梯度公式，t-SNE 中让公式 (5) 的条件概率是对称的。即初始化 $q_{i|i}=0$，对于任意的 $q_{i|j} = q_{j|i}$。\n\n### 2 数值梯度下降法\n- 在 [7] 中的概述过程，获得优化的梯度公式，如下所示:\n\n$$\n\\frac{\n\t\\partial D_{KL}(\\{p_{i,j}\\} | \\{q_{i,j}\\})\n}{\n\t\\partial_{y_t}^{(i)}\n} = 4 \\sum_j \\frac{\n\t\t(p_{i,j} - q_{i,j})\n\t}{\n\t\t(1 + ||y_t^{(i)} - y_t^{(j)}||^2)\n\t}\n\t(y_t^{(i)} - y_t^{(j)})\n\t\\tag{6}\n$$\n\n- 通过梯度下降法迭代计算局部最大值：\n\n\t$$\n\ty_{t+1}^{(i)} = y_{t}^{(i)} + \\eta(t) \\frac{\n\t\t\\partial D_{KL}(\\{p_{i,j}\\} | \\{q_{i,j}\\})\n\t}{\n\t\t\\partial_{y_t}^{(i)}\n\t}\n\t+ \\alpha(t)(y_{t}^{(i)} - y_{t-1}^{(i)})\n\t\\tag{7}\n\t$$\n\n\t- $y_t^{(i)}$ 表示迭代 t 次的解，$\\eta(t)$ 表示学习速率，$\\alpha(t)$ 表示迭代 t 次的动量。\n\t- 学习速率初始值为 $\\eta(t) = 100\\,^{[9]}$，且动能量 $\\alpha(t)$ 设定为：\n\t\n\t$$\n\t\\alpha(t) = \\begin{cases} 0.8, & t < 300 \\\\\n\t0.5, & t \\geq 300 \\end{cases}\n\t$$\n\n## 不足\n\n- t-SNE 主要用于可视化，很难用于其他目的。譬如测试集合降维，因为他没有显式的预估部分，不能在测试集合直接降维。\n- 关于核-带宽 $\\gamma$ 参数设定问题：文中展示了 $\\gamma$ 参数的大小与识别细胞亚群能力的数量关系。然而，数据驱动方式虽能实现自动聚类，但缺乏对于 $\\gamma$ 参数设定范围该如何控制的说明。\n\n## 参考\n\n[1] Maaten L, Hinton G. Visualizing data using t-SNE [J]. Journal of machine learning research, 2008, 9(Nov): 2579-2605.  \n[2] Cantor H, Simpson E, Sato V L, et al. And functional studies of peripheral t-cells binding different amounts of fluorescent anti-thy 1.2 (theta) Antibody using a fluorescence--activated cell sorter (FACS) [J]. 1975.  \n[3] Bendall S C, Nolan G P, Roederer M, et al. A deep profiler's guide to cytometry [J]. Trends in immunology, 2012, 33(7): 323-332.  \n[4] Qiu P, Simonds E F, Bendall S C, et al. Extracting a cellular hierarchy from high-dimensional cytometry data with SPADE [J]. Nature biotechnology, 2011, 29(10): 886.  \n[5] Bendall S C, Simonds E F, Qiu P, et al. Single-cell mass cytometry of differential immune and drug responses across a human hematopoietic continuum [J]. Science, 2011, 332(6030): 687-696.  \n[6] Van Der Maaten L, Postma E, Van den Herik J. Dimensionality reduction: a comparative [J]. J Mach Learn Res, 2009, 10: 66-71.  \n[7] Maaten L, Hinton G. Visualizing data using t-SNE [J]. Journal of machine learning research, 2008, 9(Nov): 2579-2605.\n[[8] Chrispher. t-SNE 完整笔记 [OL]. www.datakit.cn. 2017.](http://www.datakit.cn/blog/2017/02/05/t_sne_full.html)  \n[9] Jacobs R A. Increased rates of convergence through learning rate adaptation[J]. Neural networks, 1988, 1(4): 295-307.\n","tags":["机器学习"],"categories":["Paper"]}]