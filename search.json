[{"title":"论文 - 扩展 K-Means 算法：混合数据类型的聚类方法","url":"%2F2018%2F06%2FExtensions-to-the-k-Means-algorithm-for-custering-large-datasets-with-categorical-values.html","content":"\n{% note default %}\n原文：Extensions To The K-Means Algorithm For Clustering Large Datasets With Categorical Values  \n作者：ZHEXUE HUANG.  \n来源：Data mining and knowledge discovery, 1998, 2(3): 283-304.  \n{% endnote %}\n\n- 更新进度：\n\t- 2018.06.04: 整理原文，完成初稿；\n\t- 2018.06.05: 更新第 2 / 6 章；\n\n## 摘要\n\n在早期，大多数聚类工作主要集中在数值数据上，且它们主要是利用数值数据的固有几何特性，即数据点之间的 `距离函数` ([见附录1](#1-距离函数))。但是，数据挖掘应用程序通常涉及许多数据集，这些数据集是由混合数值属性和标称属性组成的，仅拥有数值数据的测量方法已无法满足混合数据类型的聚类工作。\n\n本论文基于经典的 K-Means 算法上，提出了两种聚类算法，分别应对 `标称域` 和 `混合数值与标称域` 属性值的聚类操作。首先介绍的是`K-Modes (K-众数)` 聚类算法，他运作的方式与 K-Means 相仿，只是它利用的是相异性度量处理标称对象，聚类中心以众数替代均值，且众数以基于频率的方法去迭代更新，直至 `聚类代价函数` 的结果最小化停止迭代。其次，是 `K-Prototype` 聚类算法，它定义了一组合的相异性度量值，进一步整合 `K-Means` 和 `K-Modes` 算法，以实现对混合数值与标称属性的对象进行聚类操作。\n\n<!-- More -->\n\n## 正文\n\n### 引入\n将数据库中的一组对象划分为同构组或集群是数据挖掘中最基本的操作。而讨论划分操作，自然离不开聚类。聚类是把每一组对象划分为一个簇，且同一簇中对象之间相似，而不同簇之间的对象相异。\n\n数据挖掘最显著的特征是处理复杂的大型数据集。特别地，数据集包含数以百万计由不同类型属性或变量描述的对象，由此数据挖掘操作和算法应充分考虑可扩展性，以应付处理不同类型的属性。\n\n在本论文中，提出的两个新聚类算法，即利用 `K-Means 范式` 对拥有标称属性的数据进行聚类。`K-Modes (K-众数)` 聚类算法，他运作的方式与 K-Means 相仿，只是它利用的是相异性度量处理标称对象，聚类中心以众数替代均值，且众数以基于频率的方法去迭代更新，直至 `聚类代价函数` 的结果最小化停止迭代。其次，是 `K-Prototype` 聚类算法，它定义了一组合的相异性度量值 $s^r + \\gamma s^c$，以实现对混合数值与标称属性的对象进行聚类操作。其中，$s^r$ 是由 `平方欧式距离` 定义的 `数值属性` 的相异性度量值，$s^c$ 是由 `两个对象间类别不匹配的数量` 定义的 `标称属性` 的相异性度量值，$\\gamma$ 是平衡数值属性和标称属性两部分的的权值，以避免偏向于某一属性。若聚类的效果更青睐于数值属性，则可以设定一个较小的 $\\gamma$ 值；反之，设定一较大的 $\\gamma$ 值。\n\n### 符号\n- 假设需要聚类的对象数据集储存在数据集 D 中。\n\t- 集合的属性 $A_1, A_2, ... , A_m$ 分别是值域 $D_1, D_2, ... , D_m$ 的描述。\n\t- 在 D 中的每个对象由元组 t 表示，$t \\in D_1 \\times D_2 \\times ... \\times D_m$。\n- 针对本文讨论的聚类问题，仅考虑两种常见数据类型：数值类型和标称类型。\n\t- 数值域的取值范围是实数域。\n\t- 在多维的密度空间中，每一个数值型的数据点都采用诸如欧式或马氏的距离度量方法。\n\t- 若值域 $D_i$ 被定义为有限、无序的标称域，则对象的比较操作只允许在 $D_i$ 中执行，即有 $a, b \\in D_i$，either a = b or $a \\neq b$。\n- 对于数据集中的每一数据对象 $X$，也可由 `属性-属性值` 的键值对表示，\n\n\t$$[A_1=x_1] \\bigwedge [A_2=x_2] \\bigwedge ... \\bigwedge [A_m=x_m]$$\n\n- 即当 $x_i \\in D_i$，for i = 1, 2, ..., m。为简单起见，这里以 $X$ 表示元组：\n\n\t$$[x_1^r, x_2^r, ...,x_p^r, x_{p+1}^c, ..., x_m^c] \\in D_1 \\times D_2 \\times ... \\times D_m$$\n\n\t> 第一个元素 p 为数值对象，其余的都是标称对象。当然，若元组中仅有一种数据类型，可表示为 $[x_1, x_2, ..., x_m]$。\n\n\t\n## 附录\n\n### 1 距离函数\n`距离函数`：关于数据点之间的距离函数，即数值属性刻画的对象相异性的距离度量。度量方法 $^{[1]}$ 包括闵可夫斯基距离 (闵氏距离)、欧几里得距离 (欧式距离) 和曼哈顿距离。\n\n令 $i=(x_{i1},x_{i2},...,x_{ih})$ 和 $j=(x_{j1},x_{j2},...,x_{jh})$ 是两个被 h 个属性描述的对象。 \n\n闵氏距离是欧式距离和曼哈顿距离的推广，定义如下：\n\n$$\nd(i, j) = \\sqrt[h](\n\t\\sum_{f=1}^h |x_{if}-x_{jf}|^{h}\n),h \\geq 1\n\\tag{1}\n$$\n\n- 当 h = 1 时，它表示 `曼哈顿距离`，也称 `城市块` 距离 (城市两点之间的街区距离，如向南 2 个街区，横过 3 个街区，共计五个街区)，其定义如下：\n\n$$\nd(i, j) = \\sum_{f=1}^h |x_{if}-x_{jf}|,h \\geq 1\n\\tag{2}\n$$\n\n- 当 h = 2 时，它表示 `欧式距离`，也称 `直线或乌鸦飞行` 距离，其定义如下：\n\n$$\nd(i, j) = \\sqrt(\\sum_{f=1}^h (x_{if}-x_{jf})^2)\n,h \\geq 1\n\\tag{3}\n$$\n\n- 当 h = $\\infty$ 时，它表示 `上确界距离`，又称 `切比雪夫距离`，其定义如下L：\n\n$$\nd(i, j) = \\lim_{h \\to \\infty} (\n\t\\sum_{f=1}^h |x_{if}-x_{jf}|^h\n)^\\frac{1}{h} = max_{f}^h |x_{if}-x_{jf}|\n\\tag{4}\n$$\n\n## 参考\n[1] Jiewei Han, Micheline Kamber and Jian Pei. 数据挖掘 (第三版) [M]. 机械工业出版社, 2018, 48-49.\n\n## 思考","tags":["K-Means"],"categories":["Paper"]}]